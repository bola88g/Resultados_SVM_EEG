{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import scandir\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaASI='C:\\\\Users\\\\boliv\\\\Desktop\\\\Ejercicio_Python\\\\Codigo_MCLJ_PCA\\\\Datos_SAC_LJMC\\\\ASI'\n",
    "rutaCO= \"C:\\\\Users\\\\boliv\\\\Desktop\\\\Ejercicio_Python\\\\Codigo_MCLJ_PCA\\\\Datos_SAC_LJMC\\\\CO\"\n",
    "# funci칩n que regresa todos los archivos en la ruta path\n",
    "def dimeArchivos(path): \n",
    "    return [obj.name for obj in scandir(path) if obj.is_file()]\n",
    "\n",
    "#Listas con los nombres de los archivos en la ruta dada\n",
    "ListaArchASI = dimeArchivos(rutaASI)\n",
    "ListaArchCO  = dimeArchivos(rutaCO)\n",
    "\n",
    "#print(len(ListaArchASI))\n",
    "#print(ListaArchASI)\n",
    "\n",
    "#Crea lista con las primeras dos letras de cada archivo, correspodientes a los nombres de los sujetos\n",
    "Name_suj_ASI = [x[0:2] for x in ListaArchASI]\n",
    "Name_suj_CO  = [x[0:2] for x in ListaArchCO]\n",
    "\n",
    "#print(Name_suj)\n",
    "\n",
    "#Crea dict para eliminar duplicados y los convierte en lista\n",
    "Name_suj_ASI = list(dict.fromkeys(Name_suj_ASI)) # ['BG','CR','EN','GF','GV','IF','IM','JE','JU','JV','LM','MI','RB','RR','VC','VV']\n",
    "Name_suj_CO = list(dict.fromkeys(Name_suj_CO))   # ['AG','AS','AZ','BE','CV','EG','GM','GV','LO','LP','LR','MN','MS','PA','TR']\n",
    "\n",
    "#print(Name_suj_ASI,type(Name_suj_ASI))\n",
    "#print(Name_suj_CO, type(Name_suj_CO))\n",
    "\n",
    "#Selecciona aleatoriamente 12 sujetos para crear los conjuntos de prueba\n",
    "ASI_12 = sorted(random.sample(Name_suj_ASI,12))\n",
    "CO_12  = sorted(random.sample(Name_suj_CO, 12))\n",
    "\n",
    "#Crea conjuntos de entrenamiento con los sujetos no seleccionados en los conjuntos de prueba\n",
    "ASI_4 = [x for x in Name_suj_ASI if x not in ASI_12]\n",
    "CO_3  = [x for x in Name_suj_CO  if x not in CO_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASI_12:  ['BG', 'EN', 'GF', 'GV', 'IF', 'IM', 'JU', 'JV', 'LM', 'MI', 'VC', 'VV'] \n",
      " CO_12:  ['AG', 'AS', 'AZ', 'BE', 'CV', 'EG', 'GM', 'LO', 'LP', 'MN', 'MS', 'TR'] \n",
      " ASI_4:  ['CR', 'JE', 'RB', 'RR'] \n",
      " CO_3:  ['GV', 'LR', 'PA']\n"
     ]
    }
   ],
   "source": [
    "print('ASI_12: ', ASI_12, '\\n', 'CO_12: ', CO_12, '\\n', 'ASI_4: ', ASI_4, '\\n', 'CO_3: ', CO_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de las rutas de los archivos por conjunto (train/test)\n",
    "Train_ASI = [rutaASI+\"\\\\\"+x for x in ListaArchASI if x[0:2] in     ASI_12]\n",
    "Test_ASI  = [rutaASI+\"\\\\\"+x for x in ListaArchASI if x[0:2] not in ASI_12]\n",
    "Train_CO  = [rutaCO+\"\\\\\"+x  for x in ListaArchCO  if x[0:2] in     CO_12]\n",
    "Test_CO   = [rutaCO+\"\\\\\"+x  for x in ListaArchCO  if x[0:2] not in CO_12]\n",
    "\n",
    "#for i in range (len(Test_ASI)):\n",
    "#    print(Test_ASI[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 92)\n"
     ]
    }
   ],
   "source": [
    "# Arma arreglo de natriz SAC\n",
    "ASI_train=[]\n",
    "CO_train=[]\n",
    "\n",
    "asi_clase = np.array ([-1])\n",
    "co_clase = np.array ([1])\n",
    "\n",
    "\n",
    "for i in Train_ASI: # ruta de archivo en conjunto dado\n",
    "    matriz_i = np.loadtxt(open(i))\n",
    "    array_sac=[]\n",
    "    for j in range(len(matriz_i)):\n",
    "        array_sac = np.concatenate((array_sac, matriz_i[j,j+1:]))\n",
    "    array_sac = np.concatenate((array_sac, asi_clase))\n",
    "    ASI_train = np.concatenate((ASI_train,array_sac))\n",
    "\n",
    "ASI_train = ASI_train.reshape(len(ASI_12)*14,92)\n",
    "\n",
    "for i in Train_CO: # ruta de archivo en conjunto dado\n",
    "    matriz_i = np.loadtxt(open(i))\n",
    "    array_sac=[]\n",
    "    for j in range(len(matriz_i)):\n",
    "        array_sac = np.concatenate((array_sac, matriz_i[j,j+1:]))\n",
    "    array_sac = np.concatenate((array_sac, co_clase))\n",
    "    CO_train = np.concatenate((CO_train,array_sac))\n",
    "\n",
    "CO_train = CO_train.reshape(len(CO_12)*14,92)\n",
    "\n",
    "#print(Arreglo_ASI[209])\n",
    "        \n",
    "SVM_train = np.concatenate((ASI_train,CO_train), axis=0)\n",
    "print(SVM_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 92)\n"
     ]
    }
   ],
   "source": [
    "# Arma arreglo de natriz SAC\n",
    "ASI_test=[]\n",
    "CO_test=[]\n",
    "\n",
    "for i in Test_ASI: # ruta de archivo en conjunto dado\n",
    "    matriz_i = np.loadtxt(open(i))\n",
    "    array_sac=[]\n",
    "    for j in range(len(matriz_i)):\n",
    "        array_sac = np.concatenate((array_sac, matriz_i[j,j+1:]))\n",
    "    array_sac = np.concatenate((array_sac, asi_clase))\n",
    "    ASI_test = np.concatenate((ASI_test,array_sac))\n",
    "\n",
    "ASI_test = ASI_test.reshape(len(ASI_4)*14,92)\n",
    "\n",
    "for i in Test_CO: # ruta de archivo en conjunto dado\n",
    "    matriz_i = np.loadtxt(open(i))\n",
    "    array_sac=[]\n",
    "    for j in range(len(matriz_i)):\n",
    "        array_sac = np.concatenate((array_sac, matriz_i[j,j+1:]))\n",
    "    array_sac = np.concatenate((array_sac, co_clase))\n",
    "    CO_test = np.concatenate((CO_test,array_sac))\n",
    "\n",
    "CO_test = CO_test.reshape(len(CO_3)*14,92)\n",
    "\n",
    "#print(Arreglo_ASI[209])\n",
    "        \n",
    "SVM_test = np.concatenate((ASI_test,CO_test), axis=0)\n",
    "print(SVM_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = SVM_train[:, 0:91]\n",
    "X_test = SVM_test[:, 0:91]\n",
    "y_train = SVM_train[:,-1]\n",
    "y_test = SVM_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Set:  (336, 91) (336,)\n",
      "Test_Set:  (98, 91) (98,)\n"
     ]
    }
   ],
   "source": [
    "print('Train_Set: ',X_train.shape, y_train.shape)\n",
    "\n",
    "print('Test_Set: ',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalo de par치metros\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boliv\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Parameters:\n",
      " {'C': 100, 'gamma': 0.01}\n",
      "Best Estimators:\n",
      " SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Se buscan los mejores par치metros para los conjuntos de entrenamiento\n",
    "clf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se ajusta el clasificador con los mejores par치metros encontrados\n",
    "clf = svm.SVC(kernel='rbf', C=100, gamma=0.01)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.80%\n"
     ]
    }
   ],
   "source": [
    "# Se realizan las predicciones en conjuntos de prueba\n",
    "clf_predictions = clf.predict(X_test)\n",
    "print(\"Accuracy: {0:.2F}%\".format(clf.score(X_test, y_test) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
